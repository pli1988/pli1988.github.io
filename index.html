<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Peter Li by pli1988</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-light.css">
    <meta name="viewport" content="width=device-width">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Peter Li</h1>
        <p></p>


        <p class="view"><a href="https://github.com/pli1988">View My GitHub Profile</a></p>

      </header>
      <section>
        <h2>
<a id="welcome" class="anchor" href="#welcome" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Welcome</h2>

<p>I'm a PhD student in the Music and Audio Research Lab (MARL) at New York University working with Juan Bello. I try to tackle problems in machine listening using methods from machine learing, deep learning, signal processing, and recently biological auditory systems. Previously, I worked on large-scale data analysis on social networks and before that empirical asset pricing and asset allocation. 


Here's a collection of projects that I've worked on in the past couple of years:</p>

<h2>
<a id="audio-and-machine-learning" class="anchor" href="#audio-and-machine-learning" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Audio and Machine Learning</h2>

<p><u>Papers</u></p>

<h3>
<a id="An RNN Model for Single Channel Source Separation with Iterative Subtraction" class="anchor" href="#An RNN Model for Single Channel Source Separation with Iterative Subtraction" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>An RNN Model for Single Channel Source Separation with Iterative Subtraction  [submited ICASSP 2018]</h3>

<p><small><i>Peter Li, Israel Malkin, Tian Wang, Kyunghyun Cho, and Juan Bello</i></small></p>

<p>In this paper, we propose a source separation model based on recurrent neural networks and a novel iterative subtraction architecture that allows us to train speaker dependent and independent separators. We describe architectures and weight sharing methods for estimating sources via masks and spectrum directly. Our approach achieves a 5 dB - 7 dB SDR a NMF baseline in a closed speaker set evaluation. Further, we show that our proposed model is robust to additional broadband noise and mixing conditions not seen during model training. <a href="./papers/ICASSP_2018.pdf">pdf</a></p>


<h3>
<a id="DeepSalience" class="anchor" href="#DeepSalience" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Deep Salience Representations for f0 Estimation in Polyphonic Music</h3>

<p><small><i>Rachel M. Bittner, Brian McFee, Justin Salamon, Peter Li, Juan P. Bello  <br> In 18th International Society for Music Information Retrieval Conference (ISMIR), Suzhou, China, Oct. 2017..</i></small></p>


<p>In this work, we describe a fully convolutional neural network for learning salience representations for estimating fundamental frequencies, trained using a large, semi-automatically generated f0 dataset. We demonstrate the effectiveness of our model for learning salience representations for both multi-f0 and melody tracking in polyphonic audio, and show that our models achieve state-of-the-art performance on several multi-f0 and melody datasets <a href="./papers/bittner_deepsalience_ismir_2017.pdf">pdf</a></p>


<h3>
<a id="Scaper" class="anchor" href="#Scaper" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Scaper: A Library for Soundscape Synthesis and Augmentation</h3>

<p><small><i>Justin Salamon, Duncan MacConnell, Mark Cartwright, Peter Li, Juan Pablo Bello  <br> In IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA), New Paltz, NY, USA, Oct. 2017.</i></small></p>


<p>Scaper is a library for soundscape synthesis and augmentation. Using scaper one can automatically synthesize soundscapes with corresponding ground truth annotations. It is useful for running controlled ML experiments (ASR, sound event detection, bioacoustic species recognition, etc.) and experiments to assess human annotation performance. It's also potentially useful for generating data for source separation experiments and for generating ambisonic soundscapes. <a href="./papers/salamon_scaper_waspaa_2017.pdf">pdf</a></p>


<p><u>Projects</u></p>

<h3>
<a id="end-to-end-source-identification-using-convolutional-neural-networks" class="anchor" href="#end-to-end-source-identification-using-convolutional-neural-networks" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>End-to-end Source Identification Using Convolutional Neural Networks</h3>



<p>Traditional methods to tackle many music information retrieval tasks typically follow a two-step architecture: feature
engineering followed by a simple learning algorithm. In these ”shallow” architectures, feature engineering and learn-
ing are typically disjoint and unrelated. Additionally, feature engineering is difficult, and typically depends on extensive
domain expertise.In this report, we present an application of convolutional neural networks for the task of automatic musical instrument identification. In this model, feature extraction and learning algorithms are trained together in an end-to-end fashion. We show that a convolutional neural network trained on raw audio can achieve performance surpassing traditional methods that rely on hand-crafted features. <a href="./papers/sourceID.pdf">pdf</a></p>

<h3>
<a id="automatic-speech-recognition-using-recurrent-neural-networks-encoderdecoder-models-with-attention" class="anchor" href="#automatic-speech-recognition-using-recurrent-neural-networks-encoderdecoder-models-with-attention" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Automatic Speech Recognition Using Recurrent Neural Networks Encoder/Decoder Models with Attention</h3>

<p>Encoder-decoder models are a powerful class of models that let us learn mappings from variable length input sequences to variable length output sequences. In this report, we investigate the efficacy of Encoder-decoder systems for the task of phoneme recognition. This was a project for the <a href="http://www.kyunghyuncho.me/home/courses/ds-ga-3001-fall-2015">Natural Language Understanding with Distributed Representations</a> course at NYU. <a href="./papers/ASR.pdf">pdf</a></p>

<h3>
<a id="speech-enhancement-with-matrix-factorization" class="anchor" href="#speech-enhancement-with-matrix-factorization" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Speech Enhancement with Matrix Factorization</h3>

<p>In this report, we explore techniques for speech enhancement using matrix factorization. We focus on enhancing speech signals corrupted with environmental noise. We implement unsupervised and "semi-supervised" methods that do not rely on access to uncorrupted speech for model training. This was a project for the <a href="https://cims.nyu.edu/~cfgranda/pages/OBDA_spring16/index.html">Optimization-based Data Analysis</a> course at NYU. <a href="./papers/speechEnhancement.pdf">pdf</a></p>

<h2>
<a id="social-networks" class="anchor" href="#social-networks" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Social Networks</h2>

<h3>
<a id="inferring-demographic-attributes-of-social-media-users-using-label-propagation" class="anchor" href="#inferring-demographic-attributes-of-social-media-users-using-label-propagation" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Inferring Demographic Attributes of Social Media Users Using Label Propagation</h3>

<p>In this paper, we propose a method to infer demographic attributes of social media users. We present a model that uses
social ties between users to infer demographic attributes. This is a graph-based algorithm that leverages homophily by spreading age labels on the the <a href="https://help.github.com/articles/basic-writing-and-formatting-syntax/#mentioning-users-and-teams" class="user-mention">@mention</a> network.</p>

<p>This is  a project that I worked on during a summer internship at HRL Laboratories. It was presented at WIN 2015. <a href="./papers/WIN.pdf">pdf</a></p>
      </section>
      <footer>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
    
  </body>
</html>
